import os
from anthropic import Anthropic

client = Anthropic()

SYSTEM_PROMPT = """Eres el agente de atenci√≥n al cliente de Zeli, una empresa de repuestos automotrices en Santiago, Veraguas, Panam√°.

Tu tono es profesional, c√°lido y eficiente. Hablas como una persona real ‚Äî no como un bot. Usas espa√±ol natural de Panam√°. Eres conciso: no m√°s de 3-4 oraciones por respuesta.

Reglas:
- Nunca digas "claro que s√≠", "por supuesto", ni frases rob√≥ticas
- Nunca uses asteriscos para √©nfasis excesivo
- No repitas lo que el cliente dijo
- No expliques lo que vas a hacer, simplemente hazlo
- Si pides informaci√≥n, pregunta una sola cosa a la vez
- Usa emojis con moderaci√≥n (1-2 m√°ximo si aplica)
- Despu√©s del primer mensaje, nunca uses frases de apertura como "¬°Hola!", "Bienvenido" o "Gracias por escribir"
- Las respuestas se vuelven m√°s cortas y directas a medida que avanza la conversaci√≥n"""

SITUATION_PROMPTS = {
    "greeting": (
        "El cliente acaba de saludar. Responde brevemente con un saludo c√°lido, "
        "pres√©ntate como Zeli y pide que te digan qu√© necesitan. "
        "Menciona el formato: pieza + marca + modelo + a√±o."
    ),
    "secondary_greeting": (
        "El cliente pregunt√≥ c√≥mo est√°s o algo similar. "
        "Responde de forma natural y pregunta en qu√© puedes ayudarle."
    ),
    "vague_intent": (
        "El cliente insinu√≥ que necesita algo pero no fue espec√≠fico. "
        "P√≠dele que te diga la pieza, marca, modelo y a√±o del veh√≠culo."
    ),
    "part_not_found": (
        "No encontramos la pieza solicitada. "
        "Informa al cliente con empat√≠a y SIEMPRE termina con un pr√≥ximo paso concreto. "
        "Prioridad: (a) ofrecerle avisarle en cuanto la consigamos, "
        "(b) sugerir una alternativa compatible si existe, "
        "(c) ofrecerle conectarlo con alguien del equipo. "
        "Nunca termines solo con 'no la encontramos' ‚Äî siempre hay un siguiente paso."
    ),
    "human_request": (
        "El cliente quiere hablar con una persona. "
        "Conf√≠rmale que alguien del equipo le va a contactar pronto. "
        "S√© breve y tranquilizador."
    ),
    "thanks": (
        "El cliente dio las gracias. "
        "Responde de forma natural y ofr√©cete por si necesita algo m√°s."
    ),
    "ack": (
        "El cliente respondi√≥ con un simple 'ok', 'entendido' o similar. "
        "Responde brevemente y pregunta si necesita algo m√°s."
    ),
    "unknown": (
        "El cliente envi√≥ un mensaje que no entendemos bien. "
        "P√≠dele que nos diga qu√© pieza necesita con el formato: "
        "pieza + marca + modelo + a√±o. S√© amable, no condescendiente."
    ),
}

FIELD_LABELS = {
    "part": "la pieza",
    "make": "la marca del veh√≠culo",
    "model": "el modelo",
    "year": "el a√±o",
}

WAIT_ACKNOWLEDGMENT = "Claro, t√≥mate tu tiempo. Aqu√≠ estamos cuando est√©s listo. üëç"


def _build_confirmation_instruction(context: dict) -> str:
    part  = context.get("part",  "?")
    make  = context.get("make",  "?")
    model = context.get("model", "?")
    year  = context.get("year",  "?")
    return (
        f"Genera un resumen de confirmaci√≥n del pedido para el cliente. "
        f"Pieza: {part}. Veh√≠culo: {make} {model} {year}. "
        f"Usa üî© para la pieza y üöó para el veh√≠culo. "
        f"Pide que confirmen con 's√≠' o que corrijan lo que est√© mal. "
        f"S√© claro y conciso. No uses frases largas."
    )


def _build_correction_reminder_instruction(context: dict) -> str:
    part  = context.get("part",  "?")
    make  = context.get("make",  "?")
    model = context.get("model", "?")
    year  = context.get("year",  "?")
    return (
        f"El cliente tiene este pedido esperando confirmaci√≥n: "
        f"{part} para {make} {model} {year}. "
        f"Respondi√≥ algo que no entendemos. "
        f"Recu√©rdale en una frase que confirme con 's√≠' o corrija lo que est√© mal."
    )


def _build_missing_fields_instruction(context: dict) -> str:
    known: dict = context.get("known", {})
    missing: list = context.get("missing", [])
    is_first = context.get("is_first_message", False)

    # Ask for exactly ONE field ‚Äî the first missing in priority order (part > make > model > year)
    next_field = missing[0] if missing else "part"
    known_parts = [f"{k} = {v}" for k, v in known.items() if v]
    known_str = ", ".join(known_parts) if known_parts else "nada a√∫n"

    brevity = (
        "S√© amable pero directo." if is_first
        else "S√© muy breve, una sola frase corta."
    )

    if next_field == "make":
        field_instruction = (
            "Pregunta por la marca del veh√≠culo con ejemplos inline ‚Äî "
            "una pregunta natural con anclas, sin lista numerada. "
            "Ejemplo del formato: '¬øEs Toyota, Hyundai, Nissan, Honda u otra marca?'"
        )
    else:
        field_label = FIELD_LABELS.get(next_field, next_field)
        field_instruction = f"Pregunta SOLO por {field_label}. Una sola frase corta."

    return (
        f"El cliente est√° pidiendo un repuesto. Ya sabemos: {known_str}. "
        f"{field_instruction} "
        f"NO saludos, NO re-presentaci√≥n, NO listas numeradas. {brevity}"
    )


def generate_response(situation: str, customer_message: str, context: dict = {}) -> str:
    if situation == "wait_acknowledgment":
        return WAIT_ACKNOWLEDGMENT

    if situation == "missing_fields":
        instruction = _build_missing_fields_instruction(context)
    elif situation == "confirmation_summary":
        instruction = _build_confirmation_instruction(context)
    elif situation == "correction_reminder":
        instruction = _build_correction_reminder_instruction(context)
    else:
        instruction = SITUATION_PROMPTS.get(situation, SITUATION_PROMPTS["unknown"])

    prompt = f"{instruction}\n\nMensaje del cliente: \"{customer_message}\""

    try:
        response = client.messages.create(
            model="claude-haiku-4-5-20251001",
            max_tokens=150,
            system=SYSTEM_PROMPT,
            messages=[{"role": "user", "content": prompt}]
        )
        return response.content[0].text.strip()
    except Exception as e:
        print(f"‚ö†Ô∏è responder error ({situation}): {e}")
        return WAIT_ACKNOWLEDGMENT


def generate_quote_presentation(options: list, parsed: dict, final_prices: list) -> str:
    part = parsed.get("part", "")
    make = parsed.get("make", "")
    model = parsed.get("model", "")
    year = parsed.get("year", "")

    options_text = ""
    for i, (opt, price) in enumerate(zip(options, final_prices), 1):
        options_text += (
            f"Opci√≥n {i}: {opt['label']}\n"
            f"  Precio: ${price}\n"
            f"  Entrega: {opt['lead_time']}\n\n"
        )

    prompt = (
        f"Presenta estas opciones de repuesto al cliente de forma natural y profesional. "
        f"Pieza: {part} para {make} {model} {year}.\n\n"
        f"{options_text}"
        f"Recomienda la mejor opci√≥n si hay una clara. "
        f"Al final SIEMPRE incluye la instrucci√≥n de que responda con el n√∫mero de opci√≥n. "
        f"S√© conciso. Usa el formato de lista numerada para las opciones."
    )

    try:
        response = client.messages.create(
            model="claude-haiku-4-5-20251001",
            max_tokens=350,
            system=SYSTEM_PROMPT,
            messages=[{"role": "user", "content": prompt}]
        )
        return response.content[0].text.strip()
    except Exception as e:
        print(f"‚ö†Ô∏è generate_quote_presentation error: {e}")
        # Fallback to structured format
        msg = f"üî© *{part} ‚Äî {make} {model} {year}*\n\nOpciones disponibles:\n\n"
        for i, (opt, price) in enumerate(zip(options, final_prices), 1):
            msg += f"*{i}.* {opt['label']} ‚Äî ${price} ¬∑ {opt['lead_time']}\n\n"
        if len(options) == 1:
            msg += "Responde con *1* para confirmar."
        else:
            nums = " o ".join(str(i) for i in range(1, len(options) + 1))
            msg += f"Responde con el n√∫mero de opci√≥n ({nums})."
        return msg
