import os
from anthropic import Anthropic

client = Anthropic()

SYSTEM_PROMPT = """Eres el agente de atenci√≥n al cliente de Zeli, una empresa de repuestos automotrices en Santiago, Veraguas, Panam√°.

Tu tono es profesional, c√°lido y eficiente. Hablas como una persona real ‚Äî no como un bot. Usas espa√±ol natural de Panam√°. Eres conciso: no m√°s de 3-4 oraciones por respuesta.

Reglas:
- Nunca digas "claro que s√≠", "por supuesto", ni frases rob√≥ticas
- Nunca uses asteriscos para √©nfasis excesivo
- No repitas lo que el cliente dijo
- No expliques lo que vas a hacer, simplemente hazlo
- Si pides informaci√≥n, pregunta una sola cosa a la vez
- Usa emojis con moderaci√≥n (1-2 m√°ximo si aplica)"""

SITUATION_PROMPTS = {
    "greeting": (
        "El cliente acaba de saludar. Responde brevemente con un saludo c√°lido, "
        "pres√©ntate como Zeli y pide que te digan qu√© necesitan. "
        "Menciona el formato: pieza + marca + modelo + a√±o."
    ),
    "secondary_greeting": (
        "El cliente pregunt√≥ c√≥mo est√°s o algo similar. "
        "Responde de forma natural y pregunta en qu√© puedes ayudarle."
    ),
    "vague_intent": (
        "El cliente insinu√≥ que necesita algo pero no fue espec√≠fico. "
        "P√≠dele que te diga la pieza, marca, modelo y a√±o del veh√≠culo."
    ),
    "part_not_found": (
        "No encontramos la pieza que busc√≥ el cliente. "
        "Dale la noticia con empat√≠a, ofrece avisarle si aparece algo, "
        "y sugiere que nos d√© m√°s detalles si aplica."
    ),
    "human_request": (
        "El cliente quiere hablar con una persona. "
        "Conf√≠rmale que alguien del equipo le va a contactar pronto. "
        "S√© breve y tranquilizador."
    ),
    "thanks": (
        "El cliente dio las gracias. "
        "Responde de forma natural y ofr√©cete por si necesita algo m√°s."
    ),
    "ack": (
        "El cliente respondi√≥ con un simple 'ok', 'entendido' o similar. "
        "Responde brevemente y pregunta si necesita algo m√°s."
    ),
    "unknown": (
        "El cliente envi√≥ un mensaje que no entendemos bien. "
        "P√≠dele que nos diga qu√© pieza necesita con el formato: "
        "pieza + marca + modelo + a√±o. S√© amable, no condescendiente."
    ),
}

FIELD_LABELS = {
    "part": "la pieza",
    "make": "la marca del veh√≠culo",
    "model": "el modelo",
    "year": "el a√±o",
}

WAIT_ACKNOWLEDGMENT = "Claro, t√≥mate tu tiempo. Aqu√≠ estamos cuando est√©s listo. üëç"


def _build_missing_fields_instruction(context: dict) -> str:
    known: dict = context.get("known", {})
    missing: list = context.get("missing", [])
    is_first = context.get("is_first_message", False)

    known_parts = [f"{k} = {v}" for k, v in known.items() if v]
    missing_labels = [FIELD_LABELS.get(f, f) for f in missing]

    known_str = ", ".join(known_parts) if known_parts else "nada a√∫n"
    missing_str = " y ".join(missing_labels)

    brevity = (
        "Es el primer intercambio ‚Äî s√© amable pero directo."
        if is_first
        else "Ya estamos en conversaci√≥n. S√© muy breve, una sola frase."
    )

    return (
        f"El cliente est√° pidiendo un repuesto. "
        f"Ya sabemos: {known_str}. "
        f"A√∫n nos falta: {missing_str}. "
        f"Pregunta SOLO lo que falta. "
        f"NO saludos, NO re-presentaci√≥n, NO listas. {brevity}"
    )


def generate_response(situation: str, customer_message: str, context: dict = {}) -> str:
    if situation == "wait_acknowledgment":
        return WAIT_ACKNOWLEDGMENT

    if situation == "missing_fields":
        instruction = _build_missing_fields_instruction(context)
    else:
        instruction = SITUATION_PROMPTS.get(situation, SITUATION_PROMPTS["unknown"])

    prompt = f"{instruction}\n\nMensaje del cliente: \"{customer_message}\""

    try:
        response = client.messages.create(
            model="claude-haiku-4-5-20251001",
            max_tokens=150,
            system=SYSTEM_PROMPT,
            messages=[{"role": "user", "content": prompt}]
        )
        return response.content[0].text.strip()
    except Exception as e:
        print(f"‚ö†Ô∏è responder error ({situation}): {e}")
        return WAIT_ACKNOWLEDGMENT


def generate_quote_presentation(options: list, parsed: dict, final_prices: list) -> str:
    part = parsed.get("part", "")
    make = parsed.get("make", "")
    model = parsed.get("model", "")
    year = parsed.get("year", "")

    options_text = ""
    for i, (opt, price) in enumerate(zip(options, final_prices), 1):
        options_text += (
            f"Opci√≥n {i}: {opt['label']}\n"
            f"  Precio: ${price}\n"
            f"  Entrega: {opt['lead_time']}\n\n"
        )

    prompt = (
        f"Presenta estas opciones de repuesto al cliente de forma natural y profesional. "
        f"Pieza: {part} para {make} {model} {year}.\n\n"
        f"{options_text}"
        f"Recomienda la mejor opci√≥n si hay una clara. "
        f"Al final SIEMPRE incluye la instrucci√≥n de que responda con el n√∫mero de opci√≥n. "
        f"S√© conciso. Usa el formato de lista numerada para las opciones."
    )

    try:
        response = client.messages.create(
            model="claude-haiku-4-5-20251001",
            max_tokens=350,
            system=SYSTEM_PROMPT,
            messages=[{"role": "user", "content": prompt}]
        )
        return response.content[0].text.strip()
    except Exception as e:
        print(f"‚ö†Ô∏è generate_quote_presentation error: {e}")
        # Fallback to structured format
        msg = f"üî© *{part} ‚Äî {make} {model} {year}*\n\nOpciones disponibles:\n\n"
        for i, (opt, price) in enumerate(zip(options, final_prices), 1):
            msg += f"*{i}.* {opt['label']} ‚Äî ${price} ¬∑ {opt['lead_time']}\n\n"
        if len(options) == 1:
            msg += "Responde con *1* para confirmar."
        else:
            nums = " o ".join(str(i) for i in range(1, len(options) + 1))
            msg += f"Responde con el n√∫mero de opci√≥n ({nums})."
        return msg
